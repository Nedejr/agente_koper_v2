#!/usr/bin/env python3
"""
Script para reprocessar APENAS o documento de Suprimentos com as corre√ß√µes
"""

import sys
from pathlib import Path

# Adiciona o diret√≥rio raiz ao path
sys.path.append(str(Path(__file__).parent))

from backend.vector_store import delete_vector_store, create_vector_store
from backend.processing import process_multiple_files


class FileWrapper:
    """Wrapper para simular um objeto file-like"""

    def __init__(self, filepath):
        self.filepath = filepath
        self.name = filepath.name
        with open(filepath, "rb") as f:
            self._content = f.read()

    def read(self):
        return self._content


def reprocess_suprimentos():
    """Reprocessa o documento de Suprimentos"""
    print("=" * 80)
    print("üîÑ REPROCESSANDO DOCUMENTO DE SUPRIMENTOS")
    print("=" * 80)

    # Caminho do documento
    doc_path = (
        Path(__file__).parent
        / "docs"
        / "Passo a passo - M√≥dulo de Suprimentos_documentacao_gerada.md"
    )

    if not doc_path.exists():
        print(f"\n‚ùå ERRO: Documento n√£o encontrado em {doc_path}")
        return False

    print(f"\nüìÑ Documento: {doc_path.name}")
    print(f"üìê Tamanho: {doc_path.stat().st_size / 1024:.2f} KB")

    try:
        # 1. LIMPAR base de dados antiga
        print("\nüóëÔ∏è  Passo 1/3: Limpando base de dados antiga...")
        try:
            delete_vector_store()
            print("   ‚úÖ Base de dados limpa")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Aviso ao limpar: {e}")

        # 2. PROCESSAR documento
        print("\nüìÑ Passo 2/3: Processando documento...")
        file_obj = FileWrapper(doc_path)
        chunks = process_multiple_files([file_obj])
        print(f"   ‚úÖ {len(chunks)} chunks criados")

        # 3. INDEXAR no vector store
        print("\nüîç Passo 3/3: Indexando chunks no vector store...")
        vector_store = create_vector_store(chunks)
        print("   ‚úÖ Chunks indexados com sucesso")

        # 4. VALIDAR
        print("\n‚úÖ VALIDA√á√ÉO:")
        collection = vector_store._collection
        total_docs = collection.count()
        print(f"   üìä Total de chunks indexados: {total_docs}")

        # Busca usando o retriever (que usa os embeddings corretos do OpenAI)
        print(f"\nüîç Testando busca por 'hist√≥rico de movimenta√ß√£o estoque':")
        try:
            retriever = vector_store.as_retriever(search_kwargs={"k": 3})
            docs = retriever.invoke("hist√≥rico de movimenta√ß√£o estoque")

            if docs:
                for i, doc in enumerate(docs, 1):
                    print(f"\n   Resultado {i}:")
                    content_preview = doc.page_content[:150].replace("\n", " ")
                    print(f"   {content_preview}...")
            else:
                print("   ‚ö†Ô∏è  Nenhum resultado encontrado")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro na busca: {e}")

        return True

    except Exception as e:
        print(f"\n‚ùå ERRO durante o reprocessamento: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("\nüöÄ INICIANDO REPROCESSAMENTO\n")

    success = reprocess_suprimentos()

    print("\n" + "=" * 80)
    if success:
        print("‚úÖ REPROCESSAMENTO CONCLU√çDO COM SUCESSO!")
        print("=" * 80)
        print("\nüí° Pr√≥ximos passos:")
        print("   1. Inicie o Streamlit: streamlit run frontend/main.py")
        print(
            "   2. Fa√ßa a pergunta: 'como verifico historico de movimenta√ß√£o do estoque?'"
        )
        print("   3. ‚úÖ V√≠deo deve iniciar em 22:49")
        print("   4. ‚úÖ Resposta deve mencionar a se√ß√£o 'Hist√≥rico de Movimenta√ß√£o'\n")
    else:
        print("‚ùå REPROCESSAMENTO FALHOU")
        print("=" * 80)
        print("\nüí° Tente:")
        print("   1. Verificar se o documento existe em docs/")
        print("   2. Verificar permiss√µes de escrita no diret√≥rio db/")
        print("   3. Executar novamente o script\n")
